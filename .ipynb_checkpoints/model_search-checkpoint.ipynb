{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model search\n",
    "\n",
    "## Getting started\n",
    "\n",
    "With training sets generated and hyperparameter sets designed, its time to search for a best performing model setup. Models will be evaluated at three levels: **1)** their ability to identify scenes with seals, **2)** retrieve seal haul outs **3)** and count individual seals. Current training classes can be displayed by running the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rock', 'glacier', 'emperor', 'marching-emperor', 'open-water', 'weddell', 'crabeater', 'crack', 'pack-ice', 'ice-sheet', 'other']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "class_names = [x[1] for x in os.walk('./training_set/training')][0]\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mcrabeater\u001b[0m/  \u001b[01;34memperor\u001b[0m/  \u001b[01;34mice-sheet\u001b[0m/         \u001b[01;34mopen-water\u001b[0m/  \u001b[01;34mpack-ice\u001b[0m/  \u001b[01;34mweddell\u001b[0m/\n",
      "\u001b[01;34mcrack\u001b[0m/      \u001b[01;34mglacier\u001b[0m/  \u001b[01;34mmarching-emperor\u001b[0m/  \u001b[01;34mother\u001b[0m/       \u001b[01;34mrock\u001b[0m/\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[01;34mcrabeater\u001b[0m/  \u001b[01;34memperor\u001b[0m/  \u001b[01;34mice-sheet\u001b[0m/         \u001b[01;34mopen-water\u001b[0m/  \u001b[01;34mpack-ice\u001b[0m/  \u001b[01;34mweddell\u001b[0m/\n",
      "\u001b[01;34mcrack\u001b[0m/      \u001b[01;34mglacier\u001b[0m/  \u001b[01;34mmarching-emperor\u001b[0m/  \u001b[01;34mother\u001b[0m/       \u001b[01;34mrock\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "# The directories should match\n",
    "%ls ./training_set/training\n",
    "print('\\n')\n",
    "%ls ./training_set/validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to find a best performing model is to train different model setups using our training set. To keep track of which combinations we have tried and, later on, performance scores at the three levels described above, we will start by creating a pandas DataFrame with model definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# generate model combinations\n",
    "combinations = {'model_architecture': ['Resnet18' for ele in range(4)] + ['Nasnet1' for ele in range(4)],\n",
    "                'training_dir': ['training_set', 'training_set_multiscale'] * 4,\n",
    "                'hyperparameter_set': ['A' for ele in range(4)] + ['B' for ele in range(4)],\n",
    "                'cv_weights': ['NO', 'NO', 'A', 'A'] * 2,\n",
    "                'output_name': ['model{}'.format(i) for i in range(1,9)]}\n",
    "\n",
    "combinations = pd.DataFrame(combinations)\n",
    "\n",
    "# create folders for resulting files\n",
    "for mdl in combinations['output_name']:\n",
    "    if not os.path.exists(\"./saved_models/{}\".format(mdl)):\n",
    "        os.makedirs(\"./saved_models/{}\".format(mdl)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then provide model combinations created above as arguments to the training script, *train_sealnet.py*. A list of required arguments can be displayed by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run train_sealnet.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iterate over combinations\n",
    "for row in combinations.iterrows():\n",
    "    print()\n",
    "    t_dir, arch, hyp_st, cv_wgt, out = row[1]['training_dir'], row[1]['model_architecture'], row[1]['hyperparameter_set'], row[1]['cv_weights'], row[1]['output_name']\n",
    "    !bash -c \"t_dir=$t_dir\" \"arch=$arch\" \"hyp_st=$hyp_st\" \"cv_wgt=$cv_wgt\" \"out=$out\"\n",
    "    !echo training $out\n",
    "    print()\n",
    "    # run training\n",
    "    !python train_sealnet.py $t_dir $arch $hyp_st $cv_wgt $out\n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation - Haulout level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the models we just trained to get measurements of precision and recall for all positive classes. For every model combination we trained, *validate_sealnet.py* will run a full validation round and write given label/correct label pairs to a .csv file. The resulting .csv file is then imported by an R script, *plot_confusion_matrix.R*, which saves a confusion matrix figure and a .csv spreadsheet with precision and recall for all classes of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validating model1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DataFrame to combine all metrics \n",
    "comb_prec_recall = pd.DataFrame()\n",
    "\n",
    "# iterate over trained models\n",
    "for row in combinations.iterrows():\n",
    "    print()\n",
    "    t_dir, arch, out = row[1]['training_dir'], row[1]['model_architecture'], row[1]['output_name']\n",
    "    # check for model file\n",
    "    if \"{}.tar\".format(out) in os.listdir('./saved_models/{}/'.format(out)): \n",
    "        !bash -c \"t_dir=$t_dir\" \"arch=$arch\" \"out=$out\"\n",
    "        !echo validating $out\n",
    "        print()\n",
    "        # run validation\n",
    "        !python validate_sealnet.py $t_dir $arch $out\n",
    "        # extract performance\n",
    "        !Rscript plot_confusion_matrix.R $out\n",
    "        # accumulate performance scores\n",
    "        comb_prec_recall = comb_prec_recall.append(pd.read_csv('./saved_models/{}/{}_prec_recall.csv'.format(out, out)))\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "# Write combined metrics to csv\n",
    "comb_prec_recall.to_csv('./saved_models/pooled_prec_recall.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Unnamed: 0  precision    recall\n",
      "0         crabeater   0.980349  0.997778\n",
      "1           weddell   0.867257  0.960784\n",
      "2           emperor   0.984104  0.994161\n",
      "3  marching-emperor   0.848000  0.883333\n",
      "0         crabeater   0.878151  0.928889\n",
      "1           weddell   0.833333  0.980392\n",
      "2           emperor   0.974249  0.994161\n",
      "3  marching-emperor   0.541463  0.925000\n",
      "0         crabeater   0.957447  1.000000\n",
      "1           weddell   0.860870  0.970588\n",
      "2           emperor   0.986957  0.994161\n",
      "3  marching-emperor   0.821429  0.958333\n",
      "0         crabeater   0.755892  0.997778\n",
      "1           weddell   0.664430  0.970588\n",
      "2           emperor   0.978479  0.995620\n",
      "3  marching-emperor   0.762963  0.858333\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
